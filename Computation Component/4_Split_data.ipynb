{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "711f8f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e7c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR      = Path(\"data\")\n",
    "P3_CSV        = DATA_DIR / \"flight_part3_ready.csv\"\n",
    "P2_META       = DATA_DIR / \"flight_part2_meta.json\"\n",
    "\n",
    "OUT_DIR       = DATA_DIR          # keep all artifacts together\n",
    "ARR_NPZ       = OUT_DIR / \"part4_Xy_arrays.npz\"\n",
    "FEATS_JSON    = OUT_DIR / \"part4_feature_names.json\"\n",
    "TRAIN_CSV     = OUT_DIR / \"part4_train_matrix.csv\"\n",
    "TEST_CSV      = OUT_DIR / \"part4_test_matrix.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8fb78f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.0 Load data\n",
    "assert P3_CSV.exists(), f\"Cannot find Part 3 data at {P3_CSV.resolve()}\"\n",
    "df_features = pd.read_csv(P3_CSV, parse_dates=[\"FL_DATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4ec78fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  4.1 Shared names \n",
    "if P2_META.exists():\n",
    "    with open(P2_META, \"r\") as f:\n",
    "        META = json.load(f)\n",
    "    LABEL_COL       = META.get(\"label_col\", \"DELAY_FLAG\")\n",
    "    LOW_CARD_COLS   = META.get(\"low_card_cols\", [\"AIRLINE\", \"WeekdayName\"])\n",
    "    HIGH_CARD_COLS  = META.get(\"high_card_cols\", [\"ORIGIN_CITY\", \"DEST_CITY\", \"ROUTE\"])\n",
    "    NUM_COLS        = META.get(\"num_cols\", [\"DISTANCE\", \"MONTH_NUM\"])\n",
    "    DATE_PARTS      = META.get(\"date_parts\", [\"FL_DATE\", \"YEAR\", \"MONTH_NUM\", \"DAY_OF_MONTH\"])\n",
    "    CARRY_ALONG     = META.get(\"carry_along\", [])\n",
    "else:\n",
    "    LABEL_COL       = \"DELAY_FLAG\"\n",
    "    LOW_CARD_COLS   = [\"AIRLINE\", \"WeekdayName\"]\n",
    "    HIGH_CARD_COLS  = [\"ORIGIN_CITY\", \"DEST_CITY\", \"ROUTE\"]\n",
    "    NUM_COLS        = [\"DISTANCE\", \"MONTH_NUM\"]\n",
    "    DATE_PARTS      = [\"FL_DATE\", \"YEAR\", \"MONTH_NUM\", \"DAY_OF_MONTH\"]\n",
    "   \n",
    "    CARRY_ALONG     = [c for c in [\"FL_NUMBER\", \"Month\"] if c in df_features.columns]\n",
    "\n",
    "ALL_NEEDED_FOR_MODEL = LOW_CARD_COLS + HIGH_CARD_COLS + NUM_COLS + [LABEL_COL]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9b437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in NUM_COLS:\n",
    "    df_features[c] = pd.to_numeric(df_features[c], errors=\"coerce\")\n",
    "df_features[LABEL_COL] = pd.to_numeric(df_features[LABEL_COL], errors=\"coerce\").astype(\"int8\")\n",
    "df_features = df_features.dropna(subset=ALL_NEEDED_FOR_MODEL).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6de54609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Train/Test Split \n",
    "train_df, test_df = train_test_split(\n",
    "    df_features,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=df_features[LABEL_COL]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59ee597e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: n=588,899  delay_rate=0.219\n",
      "TEST : n=147,225  delay_rate=0.219\n"
     ]
    }
   ],
   "source": [
    "def _desc(name, d):\n",
    "    return f\"{name}: n={len(d):,}  delay_rate={d[LABEL_COL].mean():.3f}\"\n",
    "print(_desc(\"TRAIN\", train_df))\n",
    "print(_desc(\"TEST \", test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "760767df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Encoders \n",
    "# 4.3.1 Smoothed target mean encoding for HIGH_CARD_COLS (fit on TRAIN only)\n",
    "def mean_encode(train_df, test_df, col, target, alpha=50):\n",
    "    \"\"\"\n",
    "    Smoothed target-mean encoding:\n",
    "      enc = (mean*count + alpha*global) / (count + alpha)\n",
    "    Returns (train_encoded, test_encoded).\n",
    "    \"\"\"\n",
    "    g = train_df.groupby(col)[target].agg([\"mean\", \"count\"])\n",
    "    global_mean = train_df[target].mean()\n",
    "    g[\"enc\"] = (g[\"mean\"] * g[\"count\"] + alpha * global_mean) / (g[\"count\"] + alpha)\n",
    "    mapping = g[\"enc\"]\n",
    "    tr = train_df[col].map(mapping).fillna(global_mean).astype(\"float32\")\n",
    "    te = test_df[col].map(mapping).fillna(global_mean).astype(\"float32\")\n",
    "    return tr, te\n",
    "\n",
    "for c in HIGH_CARD_COLS:\n",
    "    tr_enc, te_enc = mean_encode(train_df, test_df, c, LABEL_COL, alpha=50)\n",
    "    train_df[c + \"_ENC\"] = tr_enc\n",
    "    test_df[c + \"_ENC\"]  = te_enc\n",
    "\n",
    "ENC_HIGH_COLS = [c + \"_ENC\" for c in HIGH_CARD_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f480827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3.2 One-hot for LOW_CARD_COLS (fit on TRAIN; transform both)\n",
    "OHE_LOW = OneHotEncoder(handle_unknown=\"ignore\", sparse=False, dtype=np.float32)\n",
    "OHE_LOW.fit(train_df[LOW_CARD_COLS])\n",
    "ohe_cols = OHE_LOW.get_feature_names_out(LOW_CARD_COLS).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac4153c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4 Build design matrices \n",
    "# Numeric block: NUM_COLS + encoded highs\n",
    "ENC_NUM_COLS = NUM_COLS + ENC_HIGH_COLS\n",
    "\n",
    "def build_matrix(df_part):\n",
    "    X_low = OHE_LOW.transform(df_part[LOW_CARD_COLS])                  \n",
    "    X_num = df_part[ENC_NUM_COLS].to_numpy(np.float32)                 \n",
    "    X     = np.hstack([X_num, X_low])                                   \n",
    "    y     = df_part[LABEL_COL].to_numpy(np.int32)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = build_matrix(train_df)\n",
    "X_test,  y_test  = build_matrix(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b6ce5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shapes:\n",
      "  X_train: (588899, 29)   y_train: (588899,)\n",
      "  X_test : (147225, 29)   y_test : (147225,)\n",
      "\n",
      "First 10 feature names: ['DISTANCE', 'MONTH_NUM', 'ORIGIN_CITY_ENC', 'DEST_CITY_ENC', 'ROUTE_ENC', 'AIRLINE_Alaska Airlines Inc.', 'AIRLINE_Allegiant Air', 'AIRLINE_American Airlines Inc.', 'AIRLINE_Delta Air Lines Inc.', 'AIRLINE_Endeavor Air Inc.']\n"
     ]
    }
   ],
   "source": [
    "# Keep a human-readable column list for the design matrix\n",
    "FEATURE_NAMES = ENC_NUM_COLS + ohe_cols\n",
    "\n",
    "print(\"\\nShapes:\")\n",
    "print(\"  X_train:\", X_train.shape, \"  y_train:\", y_train.shape)\n",
    "print(\"  X_test :\", X_test.shape,  \"  y_test :\", y_test.shape)\n",
    "print(\"\\nFirst 10 feature names:\", FEATURE_NAMES[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74346851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.5 Save artifacts for Part 5 \n",
    "\n",
    "np.savez_compressed(ARR_NPZ, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n",
    "\n",
    "# Feature names (keep the exact order)\n",
    "with open(FEATS_JSON, \"w\") as f:\n",
    "    json.dump({\n",
    "        \"FEATURE_NAMES\": FEATURE_NAMES,\n",
    "        \"LOW_CARD_COLS\": LOW_CARD_COLS,\n",
    "        \"HIGH_CARD_COLS\": HIGH_CARD_COLS,\n",
    "        \"ENC_HIGH_COLS\": ENC_HIGH_COLS,\n",
    "        \"NUM_COLS\": NUM_COLS,\n",
    "        \"ENC_NUM_COLS\": ENC_NUM_COLS,\n",
    "        \"LABEL_COL\": LABEL_COL,\n",
    "        \"DATE_PARTS\": DATE_PARTS,\n",
    "        \"CARRY_ALONG\": CARRY_ALONG\n",
    "    }, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da714a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Saved:\n",
      "  Arrays: data/part4_Xy_arrays.npz\n",
      "  Feature names: data/part4_feature_names.json\n",
      "  Train matrix CSV: data/part4_train_matrix.csv\n",
      "  Test  matrix CSV: data/part4_test_matrix.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n✅ Saved:\")\n",
    "print(\"  Arrays:\", ARR_NPZ)\n",
    "print(\"  Feature names:\", FEATS_JSON)\n",
    "print(\"  Train matrix CSV:\", TRAIN_CSV)\n",
    "print(\"  Test  matrix CSV:\", TEST_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f3f82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
